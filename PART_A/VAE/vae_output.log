Training with latent size: 2
Epoch: 0, Loss: 178.78147211914063
Epoch: 1, Loss: 157.18295698242187
Epoch: 2, Loss: 152.24908707682292
Epoch: 3, Loss: 149.21676346028647
Epoch: 4, Loss: 147.12353155924478
Epoch: 5, Loss: 145.64998444010416
Epoch: 6, Loss: 144.567822265625
Epoch: 7, Loss: 143.76591160481772
Epoch: 8, Loss: 142.91961630859376
Epoch: 9, Loss: 142.42457265625
MSE for latent_size: 2: 29.9220455078125
Training with latent size: 4
Epoch: 0, Loss: 169.0372034342448
Epoch: 1, Loss: 137.76429057617187
Epoch: 2, Loss: 132.53956888020832
Epoch: 3, Loss: 129.58427568359375
Epoch: 4, Loss: 127.58319191080729
Epoch: 5, Loss: 126.17502584635416
Epoch: 6, Loss: 124.96125436197917
Epoch: 7, Loss: 123.96477732747395
Epoch: 8, Loss: 123.21265639648438
Epoch: 9, Loss: 122.51186440429687
MSE for latent_size: 4: 21.297463256835936
Training with latent size: 8
Epoch: 0, Loss: 164.55600826822916
Epoch: 1, Loss: 124.65608733723958
Epoch: 2, Loss: 116.9648422688802
Epoch: 3, Loss: 113.61002596028646
Epoch: 4, Loss: 111.55274137369791
Epoch: 5, Loss: 110.08205042317708
Epoch: 6, Loss: 108.83890439453126
Epoch: 7, Loss: 107.96014615885417
Epoch: 8, Loss: 107.06497612304688
Epoch: 9, Loss: 106.46291435546875
MSE for latent_size: 8: 13.731989721679687
Training with latent size: 16
Epoch: 0, Loss: 166.03833904622397
Epoch: 1, Loss: 122.82081118164062
Epoch: 2, Loss: 113.97418440755209
Epoch: 3, Loss: 110.22526959635417
Epoch: 4, Loss: 107.93293666992187
Epoch: 5, Loss: 106.28638971354167
Epoch: 6, Loss: 105.05323002929687
Epoch: 7, Loss: 104.07800989583333
Epoch: 8, Loss: 103.15581682942708
Epoch: 9, Loss: 102.44219262695313
MSE for latent_size: 16: 11.2181921875
Training with latent size: 32
Epoch: 0, Loss: 170.79650921223958
Epoch: 1, Loss: 125.30435932617188
Epoch: 2, Loss: 115.86356513671875
Epoch: 3, Loss: 111.94029778645833
Epoch: 4, Loss: 109.57291350911458
Epoch: 5, Loss: 108.03591018880208
Epoch: 6, Loss: 106.68852809244791
Epoch: 7, Loss: 105.5559041015625
Epoch: 8, Loss: 104.64592228190104
Epoch: 9, Loss: 103.76354086914063
MSE for latent_size: 32: 12.014886456298829
Training with latent size: 64
Epoch: 0, Loss: 173.9913487141927
Epoch: 1, Loss: 129.09816653645834
Epoch: 2, Loss: 119.15810022786458
Epoch: 3, Loss: 114.13717464192709
Epoch: 4, Loss: 110.83658587239583
Epoch: 5, Loss: 108.73492179361979
Epoch: 6, Loss: 107.32833450520833
Epoch: 7, Loss: 106.13901000976563
Epoch: 8, Loss: 105.2727760579427
Epoch: 9, Loss: 104.49366596679687
MSE for latent_size: 64: 12.24203358154297